from Bio import SeqIO
import numpy as np
from plantbert.mlm.convnet import ConvNetModel
import torch
from transformers import AutoTokenizer
import sys


checkpoint_path = sys.argv[1]
output_path = sys.argv[2]

genome = SeqIO.to_dict(SeqIO.parse("../../data/mlm/tair10.fa", format="fasta"))
window_size = 1000000
center = 3566700
seq = str(genome["Chr5"][center-window_size//2:center+window_size//2].seq)

tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)
model = ConvNetModel.from_pretrained(checkpoint_path)
model.eval()
# # chr5:3,566,700-3,567,700
#seq = "ATAAACATATCATAAATAAGATCAATATTAATAAAATAAATAGTTTTTTTTACGGGACGGATTGGCGGGACGAGTTTAGCAGGACGTAACTTAATAACAATTGTAAACTATAAAATAAAAATATTTTATAGATAGATACAATTTGCAAACTTTTATATATACTAACTTAAAAAAAAAATATTGTCCCCTGCGGTATAAGACGGGTTAAAAATCTAGTTGTTATTATTAAAGGAAATAAAATATCCTCATAAAACAATTTGTTGTAATCTATCTTTGGGCTAATGTTCTTATCCTACAAGACGAACCCTGACCGTATTCGTCGTAGAAAAAAAATTGCTTCGATCCCATCATTGAGTTCAATAATCGGCGCACAAAGGCCGATTCATAAAAACTCTAGGCCCATTAAAGTAAAGCCCATTCTCAACCCTATCCAGTCTCCCTGTATATATATATTTACGACACCAACCCAGCGTTGATATTTAATTTTCTTCAGTCAGAGATTTCGAAACCCTAGTCGATTTCGAGATCCAACTAACTCTGCTCCTTATCTCAGGTAAAATTCTCGCTCGAGAACTCAATTGCTTATCCAAAGTTCCAACTGAAGATGCTTTCCTACTGAATCTTAGGTTAATGTTTTGGATTTGGAATCTTACCCGAAATTTCTCTGCAGCTTGTTGAATTTGCGAAGTATGGGAGACGCTAGAGACAACGAAGCCTACGAGGAGGAGCTCTTGGACTATGAAGAAGAAGACGAGAAGGTCCCAGATTCTGGAAACAAAGTTAACGGCGAAGCTGTGAAAAAGTGAGTTTTATGGTTTCCTCGATATGTTTCATGTATACTACTGTGTGTTTAAATTTGTCGATTCTTAGATTACTACTTGATAACAAGTAGCAGTATGTGTTTAATTAGTTGCTTAACATATAACAATTGACTGAGTTCTTCATTGCTATAATTCCTGAAACCCACCCAATATTAGACTGTCGTGTGTTTCTCATATTG"
print(len(seq))
input_ids = tokenizer(seq, return_tensors="pt")["input_ids"]

with torch.no_grad():
    embedding = model(input_ids=input_ids).last_hidden_state[0].numpy()
print(embedding.shape)

np.save(output_path, embedding)