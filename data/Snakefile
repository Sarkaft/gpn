from Bio import SeqIO
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from tqdm import tqdm
tqdm.pandas(desc="my bar!")

import matplotlib
matplotlib.use('pdf')


configfile: "config.yaml"


tracks = pd.read_csv(config["tracks_path"], sep="\t", index_col=0)
tracks = tracks[~tracks.index.str.startswith("DGF")]
print(tracks)

REGION_SIZE = 200
FLANK_SIZE = 400
TOTAL_SIZE = REGION_SIZE + 2 * FLANK_SIZE
genome_name = "BSgenome.Athaliana.TAIR.TAIR10FILT.masked"

split_chromosomes = {
    "train": ["Chr1", "Chr3", "Chr5"],
    "val": ["Chr4"],
    "test": ["Chr2"],
}
splits = split_chromosomes.keys()

rule all:
    input:
        "plots/positive_proportion.pdf",
        #expand("datasets/{split}.parquet", split=splits),
        #"pos_regions/intersection.bed",
        #expand("pos_regions/{split}/intersection.bed", split=splits),
        #"all.bed",
        #"plots/n_tracks_per_feature_type.pdf",
        #expand("peaks/{track_name}.bed", track_name=tracks.index),
        #expand("processed_peaks/{track_name}.bed", track_name=tracks.index),
        #expand("pos_regions/{track_name}/all.bed", track_name=tracks.index),
        #expand("neg_regions/{track_name}/{split}.bed", track_name=tracks.index, split=splits),
        #"neg_regions/all/intersection.bed",


rule download_track:
    output:
        "peaks/{track_name}.bed",
    params:
        track_url = lambda wildcards: tracks.loc[wildcards["track_name"]].track_url
    shell:
        "wget {params.track_url} -O {output}"


rule plot_track_stats:
    input:
        expand("peaks/{track_name}.bed", track_name=tracks.index),
    output:
        "plots/n_tracks_per_feature_type.pdf",
        "plots/n_peaks_per_track.pdf",
        "plots/peak_width.pdf",
    run:
        df1s = []
        df2s = []
        for i, track_name in enumerate(tracks.index):
            if i % 10 == 0: print(i)
            df = pd.read_csv(input[i], sep="\t", header=None, usecols=[0, 1, 2])
            df["peak_width"] = df[2] - df[1]
            df["track_name"] = track_name
            df = df[["track_name", "peak_width"]]
            df1s.append(df)
            df2s.append(df.groupby("track_name").size().to_frame("n_peaks").reset_index())
        df1 = pd.concat(df1s, ignore_index=True)
        df2 = pd.concat(df2s, ignore_index=True)
        for df in [df1, df2]:
            df["feature_type"] = df.track_name.str.split("_").str[0]
            df.feature_type.replace({
                "DHS": "DNase I hypersensitive site",
                "DGF": "DNase I digital genomic footprinting",
                "HM": "Histone modification",
                "TFBS": "TF binding site",
               }, inplace=True)
        print(df1)
        print(df2)

        sns.countplot(data=df2, y="feature_type")
        plt.savefig(output[0], bbox_inches='tight')
        plt.close()

        #sns.displot(data=df2, col="feature_type", x="n_peaks", bins=20, facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[1], bbox_inches='tight')
        #plt.close()

        #sns.displot(data=df1, col="feature_type", x="peak_width", bins=20,  facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[2], bbox_inches='tight')
        #plt.close()

        #sns.displot(data=df2, col="feature_type", x="n_peaks", kind="kde", height=3, facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[1], bbox_inches='tight')
        #plt.close()

        #sns.displot(data=df1, col="feature_type", x="peak_width", kind="kde", height=3, aspect=2, facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[2], bbox_inches='tight')
        #plt.close()

        #sns.boxplot(data=df2, y="feature_type", x="n_peaks")
        #plt.savefig(output[1], bbox_inches='tight')
        #plt.close()

        #sns.boxplot(data=df1, y="feature_type", x="peak_width")
        #plt.savefig(output[2], bbox_inches='tight')
        #plt.close()

        g = sns.catplot(data=df2, row="feature_type", y="n_peaks", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[1], bbox_inches='tight')
        plt.close()

        g = sns.catplot(data=df1, row="feature_type", y="peak_width", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[2], bbox_inches='tight')
        plt.close()


rule process_peaks:
    input:
        "peaks/{track_name}.bed",
        config["chrom_sizes_path"],
    output:
        "processed_peaks/{track_name}.bed",
    run:
        bed = pd.read_csv(input[0], sep="\t", header=None, usecols=[0, 1, 2]).rename(columns={0: "chromosome", 1: "start", 2: "end"})
        chrom_sizes = pd.read_csv(input[1], sep="\t", header=None, index_col=0)
        bed = bed[bed.chromosome.isin(chrom_sizes.index.values)]
        bed["track_name"] = wildcards["track_name"]
        center = (bed.start + bed.end) // 2
        bed.start = center - REGION_SIZE // 2
        bed.end = center + REGION_SIZE // 2
        bed.to_csv(output[0], sep="\t", header=False, index=False)


rule merge_tracks:
    input:
        expand("processed_peaks/{track_name}.bed", track_name=tracks.index),
    output:
        "all.unsorted.bed",
    shell:
        "cat {input} > {output}"


rule sort_track:
    input:
        "all.unsorted.bed",
    output:
        "all.bed",
    shell:
        "bedtools sort -i {input} > {output}"


rule make_windows:
    input:
        config["chrom_sizes_path"],
    output:
        "windows.bed"
    shell:
        "bedtools makewindows -g {input} -w {REGION_SIZE} > {output}"


rule bedtools_intersect_and_slop:
    input:
        "windows.bed",
        "all.bed",
        config["chrom_sizes_path"],
    output:
        "pos_regions/all/intersection.bed",
    shell:
        """bedtools map -a {input[0]} -b {input[1]} -f 0.5 -o distinct -c 4 | bedtools slop -i stdin -g {input[2]} -b {FLANK_SIZE} | awk '$3-$2 == {TOTAL_SIZE}' | awk '$4 != "."' > {output}"""


#rule split_regions:
#    input:
#        "pos_regions/all/intersection.bed",
#    output:
#        expand("pos_regions/{split}/intersection.bed", split=splits),
#    run:
#        df = pd.read_csv(input[0], sep="\t", header=None, names=["chromosome", "start", "end", "features"])
#        print(df)
#        for i, split in enumerate(splits):
#            if split == "train":
#                mask = (df.chromosome.isin(["Chr1", "Chr3", "Chr5"]) | ((df.chromosome=="Chr2") & (df.start < 15000000)))
#            elif split == "val":
#                mask = ((df.chromosome=="Chr2") & (df.start >= 15000000))
#            elif split == "test":
#                mask = (df.chromosome=="Chr4")
#            print(split, mask.mean())
#            df[mask].to_csv(output[i], sep="\t", header=False, index=False)


rule sample_negative_seqs:
    input:
        "pos_regions/all/intersection.bed",
    output:
        "neg_regions/all/intersection.bed",
        "pos_regions/all/seq.fa",
        "neg_regions/all/seq.fa",
    shell:
        "Rscript sample_negative_seqs.R {genome_name} {input} {output}"


rule make_dataset:
    input:
        "pos_regions/all/intersection.bed",
        "neg_regions/all/intersection.bed",
        "pos_regions/all/seq.fa",
        "neg_regions/all/seq.fa",
    output:
        expand("datasets/{split}.parquet", split=splits),
    run:
        track_list = tracks.index.values.tolist()

        pos_regions = pd.read_csv(input[0], sep="\t", header=None, names=["chromosome", "start", "end", "features"])
        pos_regions["strand"] = "+"

        pos_seq = []
        pos_seq_rc = []
        for record in SeqIO.parse(input[2], "fasta"):
            pos_seq.append(str(record.seq))
            pos_seq_rc.append(str(record.seq.reverse_complement()))
        pos_regions["seq"] = pos_seq

        pos_regions.loc[:, track_list] = np.uint8(0)
        pos_regions.features = pos_regions.features.apply(lambda x: x.split(','))
        for index, row in tqdm(pos_regions.iterrows(), total=pos_regions.shape[0]):
            pos_regions.loc[index, row.features] = np.uint8(1)
        pos_regions.drop(columns="features", inplace=True)


        neg_regions = pd.read_csv(input[1], sep="\t", header=None, names=["chromosome", "start", "end"])
        neg_regions["strand"] = "+"

        neg_seq = []
        neg_seq_rc = []
        for record in SeqIO.parse(input[3], "fasta"):
            neg_seq.append(str(record.seq))
            neg_seq_rc.append(str(record.seq.reverse_complement()))
        neg_regions["seq"] = neg_seq
        neg_regions.loc[:, track_list] = np.uint8(0)

        regions = pd.concat([pos_regions, neg_regions], ignore_index=True)
        print(regions)
        regions_rc = regions.copy()
        regions_rc["strand"] = "-"
        regions_rc["seq"] = pos_seq_rc + neg_seq_rc

        regions = pd.concat([regions, regions_rc], ignore_index=True)
        print(regions)

        for i, split in enumerate(splits):
            if split == "train":
                mask = (regions.chromosome.isin(["Chr1", "Chr3", "Chr5"]) | ((regions.chromosome=="Chr2") & (regions.start < 15000000)))
            elif split == "val":
                mask = ((regions.chromosome=="Chr2") & (regions.start >= 15000000))
            elif split == "test":
                mask = (regions.chromosome=="Chr4")
            print(split, mask.mean())
            regions[mask].to_parquet(output[i], index=False)


rule plot_class_balance:
    input:
        "datasets/test.parquet",
    output:
        "plots/positive_proportion.pdf",
        "plots/log10_positive_proportion.pdf",
    run:
        d = pd.read_parquet(input[0])
        features = [col for col in d.columns.values if col not in ["chromosome", "start", "end", "strand", "seq"]]
        p = d[features].mean().to_frame("positive_proportion")
        print(p)
        p["feature_type"] = p.index.str.split("_").str[0]
        p.feature_type.replace({
            "DHS": "DNase I hypersensitive site",
            "DGF": "DNase I digital genomic footprinting",
            "HM": "Histone modification",
            "TFBS": "TF binding site",
        }, inplace=True)
        print(p)
        p["log10_positive_proportion"] = p.positive_proportion.apply(np.log10)
        print(p)

        g = sns.catplot(data=p, row="feature_type", y="positive_proportion", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[0], bbox_inches='tight')
        plt.close()

        g = sns.catplot(data=p, row="feature_type", y="log10_positive_proportion", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[1], bbox_inches='tight')
