from Bio.Seq import Seq
from Bio import SeqIO
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns
from tqdm import tqdm
tqdm.pandas(desc="my bar!")

import matplotlib
matplotlib.use('pdf')


configfile: "config.yaml"


tracks = pd.read_csv(config["tracks_path"], sep="\t", index_col=0)
tracks = tracks[~tracks.index.str.startswith("DGF")]
print(tracks)

REGION_SIZE = 200
FLANK_SIZE = 400
TOTAL_SIZE = REGION_SIZE + 2 * FLANK_SIZE
genome_name = "BSgenome.Athaliana.TAIR.TAIR10FILT.masked"

splits = ["train", "val", "test"]

rule all:
    input:
        #"intersection.seq.bed",
        "plots/positive_proportion.pdf",
        expand("datasets/{split}.parquet", split=splits),
        #"pos_regions/intersection.bed",
        #expand("pos_regions/{split}/intersection.bed", split=splits),
        #"all.bed",
        #"plots/n_tracks_per_feature_type.pdf",
        #expand("peaks/{track_name}.bed", track_name=tracks.index),
        #expand("processed_peaks/{track_name}.bed", track_name=tracks.index),
        #expand("pos_regions/{track_name}/all.bed", track_name=tracks.index),
        #expand("neg_regions/{track_name}/{split}.bed", track_name=tracks.index, split=splits),
        #"neg_regions/all/intersection.bed",


rule download_track:
    output:
        "peaks/{track_name}.bed",
    params:
        track_url = lambda wildcards: tracks.loc[wildcards["track_name"]].track_url
    shell:
        "wget {params.track_url} -O {output}"


rule plot_track_stats:
    input:
        expand("peaks/{track_name}.bed", track_name=tracks.index),
    output:
        "plots/n_tracks_per_feature_type.pdf",
        "plots/n_peaks_per_track.pdf",
        "plots/peak_width.pdf",
    run:
        df1s = []
        df2s = []
        for i, track_name in enumerate(tracks.index):
            if i % 10 == 0: print(i)
            df = pd.read_csv(input[i], sep="\t", header=None, usecols=[0, 1, 2])
            df["peak_width"] = df[2] - df[1]
            df["track_name"] = track_name
            df = df[["track_name", "peak_width"]]
            df1s.append(df)
            df2s.append(df.groupby("track_name").size().to_frame("n_peaks").reset_index())
        df1 = pd.concat(df1s, ignore_index=True)
        df2 = pd.concat(df2s, ignore_index=True)
        for df in [df1, df2]:
            df["feature_type"] = df.track_name.str.split("_").str[0]
            df.feature_type.replace({
                "DHS": "DNase I hypersensitive site",
                "DGF": "DNase I digital genomic footprinting",
                "HM": "Histone modification",
                "TFBS": "TF binding site",
               }, inplace=True)
        print(df1)
        print(df2)

        sns.countplot(data=df2, y="feature_type")
        plt.savefig(output[0], bbox_inches='tight')
        plt.close()

        #sns.displot(data=df2, col="feature_type", x="n_peaks", bins=20, facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[1], bbox_inches='tight')
        #plt.close()

        #sns.displot(data=df1, col="feature_type", x="peak_width", bins=20,  facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[2], bbox_inches='tight')
        #plt.close()

        #sns.displot(data=df2, col="feature_type", x="n_peaks", kind="kde", height=3, facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[1], bbox_inches='tight')
        #plt.close()

        #sns.displot(data=df1, col="feature_type", x="peak_width", kind="kde", height=3, aspect=2, facet_kws=dict(sharex=False, sharey=False))
        #plt.savefig(output[2], bbox_inches='tight')
        #plt.close()

        #sns.boxplot(data=df2, y="feature_type", x="n_peaks")
        #plt.savefig(output[1], bbox_inches='tight')
        #plt.close()

        #sns.boxplot(data=df1, y="feature_type", x="peak_width")
        #plt.savefig(output[2], bbox_inches='tight')
        #plt.close()

        g = sns.catplot(data=df2, row="feature_type", y="n_peaks", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[1], bbox_inches='tight')
        plt.close()

        g = sns.catplot(data=df1, row="feature_type", y="peak_width", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[2], bbox_inches='tight')
        plt.close()


rule process_peaks:
    input:
        "peaks/{track_name}.bed",
        config["chrom_sizes_path"],
    output:
        "processed_peaks/{track_name}.bed",
    run:
        bed = pd.read_csv(input[0], sep="\t", header=None, usecols=[0, 1, 2]).rename(columns={0: "chromosome", 1: "start", 2: "end"})
        chrom_sizes = pd.read_csv(input[1], sep="\t", header=None, index_col=0)
        bed = bed[bed.chromosome.isin(chrom_sizes.index.values)]
        bed["track_name"] = wildcards["track_name"]
        bed.to_csv(output[0], sep="\t", header=False, index=False)


rule merge_tracks:
    input:
        expand("processed_peaks/{track_name}.bed", track_name=tracks.index),
    output:
        "processed_peaks/all.bed",
    shell:
        "cat {input} | bedtools sort -i stdin > {output}"


rule make_windows:
    input:
        config["chrom_sizes_path"],
    output:
        "windows.bed"
    shell:
        "bedtools makewindows -g {input} -w {REGION_SIZE} > {output}"


rule bedtools_intersect_and_slop:
    input:
        "windows.bed",
        "processed_peaks/all.bed",
        config["chrom_sizes_path"],
    output:
        "intersection.bed",
    shell:
        """bedtools map -a {input[0]} -b {input[1]} -f 0.5 -o distinct -c 4 | bedtools slop -i stdin -g {input[2]} -b {FLANK_SIZE} | awk '$3-$2 == {TOTAL_SIZE}' > {output}"""

rule add_seq:
    input:
        "intersection.bed",
        "reference/tair10.fa",
    output:
        "intersection.seq.bed",
    shell:
        "bedtools getfasta -fi {input[1]} -bed {input[0]} -tab -bedOut > {output}"


# TODO: should shuffle the dataset row order before adding the reverse complements

rule make_dataset:
    input:
        "intersection.seq.bed",
    output:
        expand("datasets/{split}.parquet", split=splits),
    run:
        track_list = tracks.index.values.tolist()

        regions = pd.read_csv(input[0], sep="\t", header=None, names=["chromosome", "start", "end", "features", "seq"])
        print(regions.shape)
        regions = regions[~(regions.seq.str.contains("[^ACTG]"))]
        print(regions.shape)
        regions = regions.sample(frac=1, random_state=42)
        regions["strand"] = "+"
        regions = regions[["chromosome", "start", "end", "strand", "seq", "features"]]
        regions.loc[:, track_list] = np.uint8(0)
        regions.features = regions.features.apply(lambda x: x.split(','))
        for index, row in tqdm(regions.iterrows(), total=regions.shape[0]):
            if not '.' in row.features:  # this means not empty
                regions.loc[index, row.features] = np.uint8(1)
        regions.drop(columns="features", inplace=True)
        print(regions)

        regions_rc = regions.copy()
        regions_rc["strand"] = "-"
        regions_rc["seq"] = regions_rc.seq.apply(lambda x: str(Seq(x).reverse_complement()))

        regions = pd.concat([regions, regions_rc], ignore_index=True)
        print(regions)
        print(regions.columns)

        for i, split in enumerate(splits):
            if split == "train":
                mask = (regions.chromosome.isin(["Chr1", "Chr2", "Chr3"]) | ((regions.chromosome=="Chr4") & (regions.start < 12000000)))
            elif split == "val":
                mask = ((regions.chromosome=="Chr4") & (regions.start >= 12000000))
            elif split == "test":
                mask = (regions.chromosome=="Chr5")
            print(split, mask.mean())
            regions[mask].to_parquet(output[i], index=False)


rule plot_class_balance:
    input:
        "datasets/test.parquet",
    output:
        "plots/positive_proportion.pdf",
        "plots/log10_positive_proportion.pdf",
    run:
        d = pd.read_parquet(input[0])
        features = [col for col in d.columns.values if col not in ["chromosome", "start", "end", "strand", "seq"]]
        p = d[features].mean().to_frame("positive_proportion")
        print(p)
        p["feature_type"] = p.index.str.split("_").str[0]
        p.feature_type.replace({
            "DHS": "DNase I hypersensitive site",
            "DGF": "DNase I digital genomic footprinting",
            "HM": "Histone modification",
            "TFBS": "TF binding site",
        }, inplace=True)
        print(p)
        p["log10_positive_proportion"] = p.positive_proportion.apply(np.log10)
        print(p)

        g = sns.catplot(data=p, row="feature_type", y="positive_proportion", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[0], bbox_inches='tight')
        plt.close()

        g = sns.catplot(data=p, row="feature_type", y="log10_positive_proportion", kind="box", height=3, sharex=False, sharey=False, showfliers=False)
        g.set_titles(col_template="{col_name}", row_template="{row_name}")
        plt.savefig(output[1], bbox_inches='tight')


rule filter_chrom_sizes:
    input:
        config["chrom_sizes_path"],
    output:
        "chrom.sizes.lm.train",
    shell:
        "grep -v Chr5 {input} > {output}"


rule make_windows_lm_raw:
    input:
        "chrom.sizes.lm.train",
    output:
        "windows.lm.train.raw.bed"
    shell:
        "bedtools makewindows -g {input} -w 1000 -s 200 > {output}"


rule make_windows_lm_pos:
    input:
        "windows.lm.train.raw.bed"
    output:
        "windows.lm.train.pos.bed"
    shell:
        """awk '{{print $0 "\t.\t.\t+"}}' {input} > {output}"""


rule make_windows_lm_neg:
    input:
        "windows.lm.train.raw.bed"
    output:
        "windows.lm.train.neg.bed"
    shell:
        """awk '{{print $0 "\t.\t.\t-"}}' {input} > {output}"""


rule make_windows_lm:
    input:
        "windows.lm.train.pos.bed",
        "windows.lm.train.neg.bed",
    output:
        "windows.lm.train.bed",
    shell:
        "cat {input} > {output}"


rule extract_seq_lm:
    input:
        "windows.lm.train.bed",
    output:
        "lm.train.seqs.txt",
    shell:
        """bedtools getfasta -fi reference/tair10.fa -bed {input} -s | grep -v "[^ACTG]" > {output}"""
